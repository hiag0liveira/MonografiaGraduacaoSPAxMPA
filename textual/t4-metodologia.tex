\chapter{Metodologia}
\label{cap:metodologia}

Este capítulo detalha a abordagem metodológica adotada para a condução do trabalho. A metodologia foi estruturada em quatro etapas principais: o levantamento teórico para fundamentar a pesquisa, o mapeamento sistemático da literatura para identificar o estado da arte, o desenvolvimento de um estudo de caso prático para a coleta de dados empíricos e, por fim, os procedimentos de teste e análise utilizados para comparar as arquiteturas \acrshort{csr} e \acrshort{ssr}.


\section{Levantamento Teórico}
\label{sec:levantamento-teorico}

O levantamento teórico consistiu na revisão e sistematização dos principais conceitos, tecnologias e práticas relacionadas à renderização de conteúdo em aplicações web, com foco nas abordagens de \english{\acrfull{csr}} e \english{\acrfull{ssr}}. Essa etapa teve como objetivo fornecer o embasamento necessário para o desenvolvimento do estudo de caso e da análise comparativa proposta neste trabalho.

A fundamentação iniciou-se com a exploração dos princípios do desenvolvimento web moderno, incluindo a arquitetura cliente-servidor, o funcionamento do protocolo \acrshort{http} e as tecnologias essenciais do \textit{frontend}: \acrshort{html}, \acrshort{css} e JavasSript. Estes elementos formam a base para compreender como as estratégias de renderização operam, tanto no lado do cliente quanto no lado do servidor.

Em seguida, foram estudadas em detalhes as abordagens \acrshort{csr} e \acrshort{ssr}. A renderização no lado do cliente (\acrshort{csr}) foi analisada quanto ao seu funcionamento típico em aplicações \english{\acrfull{spa}}, caracterizadas por uma única página carregada inicialmente, com atualizações dinâmicas de conteúdo via JavaScript. Essa abordagem oferece vantagens como maior interatividade e fluidez na navegação, além de transições rápidas entre páginas internas. No entanto, apresenta desvantagens como maior tempo de carregamento inicial e limitações de indexação por mecanismos de busca.

Por outro lado, a renderização no lado do servidor (\acrshort{ssr}) foi abordada sob a ótica de desempenho inicial otimizado e maior compatibilidade com \acrshort{seo}, pois o conteúdo é entregue já renderizado ao navegador. Essa abordagem é comumente utilizada em aplicações do tipo \english{\acrfull{mpa}}, que possuem múltiplas páginas distintas e se beneficiam da pré-renderização para melhorar a performance inicial, a acessibilidade e a visibilidade em mecanismos de busca. Como contraponto, o SSR demanda maior processamento no servidor e pode aumentar a complexidade da infraestrutura.

O levantamento teórico foi aprofundado com uma análise dos principais \textit{frameworks} e bibliotecas que materializam as arquiteturas \acrshort{csr} e \acrshort{ssr}. Foi dada ênfase especial ao \textit{React}, como principal expoente da renderização no lado do cliente, e ao \textit{Next.js}, \textit{framework} que o estende para possibilitar uma renderização robusta no lado do servidor. A discussão foi enriquecida com o estudo do ecossistema de outras ferramentas, como \textit{Vue.js} e \textit{Angular}, para consolidar a compreensão sobre os impactos de cada abordagem na experiência do usuário (\acrshort{ux}), no \acrshort{seo}, na acessibilidade e na interatividade.

Essa base teórica consolidada foi, portanto, essencial para embasar as escolhas metodológicas, delimitar o escopo do mapeamento da literatura e, principalmente, para orientar o desenvolvimento e a avaliação do estudo de caso prático detalhado a seguir.

\section{Mapeamento Sistemático da Literatura}
\label{sec:mapemento-sistematico-da-literatura}

O mapeamento sistemático da literatura teve como objetivo identificar, selecionar e analisar estudos acadêmicos relevantes que abordassem comparações entre as abordagens de renderização \english{\acrshort{csr}} e \english{\acrshort{ssr}} no contexto do desenvolvimento de aplicações web. Essa etapa foi essencial para compreender o estado da arte, bem como identificar lacunas e oportunidades para a realização do estudo de caso proposto neste trabalho.

A estratégia de busca foi estruturada com o apoio da metodologia \textit{PICOC}, que define os elementos População, Intervenção, Comparação, Resultado e Contexto, com o intuito de guiar a construção das expressões de busca e garantir abrangência e precisão nos resultados. As principais bases de dados utilizadas incluíram Periódicos Capes e Scopus, por oferecerem amplo acervo e suporte a pesquisas refinadas.

Foram utilizadas expressões booleanas combinando termos como \textit{Client-Side Rendering}, \textit{Server-Side Rendering}, \textit{Web Performance}, \textit{SEO}, \textit{UX} e \textit{Frontend Architecture}. Após a aplicação dos critérios de inclusão e exclusão, os artigos resultantes foram classificados e analisados de acordo com sua relevância, tipo de abordagem estudada, metodologias utilizadas e principais conclusões.

A seleção final contemplou trabalhos que abordavam métricas de desempenho, tempo de carregamento, interatividade, \acrshort{seo} e experiência do usuário. Além disso, foram considerados estudos que analisavam o uso de frameworks modernos como \textit{React}, \textit{Next.js}, \textit{Nuxt.js} e \textit{Angular Universal}, além de pesquisas aplicadas em contextos reais de produção.

Como resultado, foi possível consolidar uma visão abrangente sobre os desafios, vantagens e limitações de cada abordagem, fornecendo subsídios importantes para a execução do estudo de caso prático apresentado nos capítulos seguintes. O mapeamento sistemático também evidenciou a escassez de estudos nacionais aplicados ao tema, reforçando a relevância deste trabalho no cenário acadêmico e profissional brasileiro.


\section{Estudo de Caso Prático}
\label{sec:estudo-de-caso-pratico}

Para materializar a análise comparativa proposta, esta pesquisa se baseia em um estudo de caso prático: o desenvolvimento de uma aplicação web de notícias sobre tecnologia. Este contexto foi escolhido por ser altamente representativo de um vasto segmento de aplicações focadas em conteúdo, onde a velocidade de carregamento inicial e a otimização para mecanismos de busca (\acrshort{seo}) são fatores críticos para a retenção de usuários e o sucesso do produto.

Com o objetivo de estabelecer condições equivalentes para comparação, foram desenvolvidas duas versões funcionalmente idênticas da plataforma. A primeira utiliza \acrfull{csr}, implementada com a biblioteca \textit{React} (\acrshort{spa}), enquanto a segunda adota \acrfull{ssr}, com o \textit{framework Next.js} (\acrshort{mpa}). Ambas as versões consomem dados da mesma \textit{API} externa de notícias e apresentam a mesma interface e funcionalidades como listagem de artigos, busca e visualização de detalhes, assegurando que as diferenças de desempenho observadas possam ser diretamente atribuídas à arquitetura de renderização empregada.

Cada versão foi implementada seguindo os princípios fundamentais da sua respectiva abordagem. Na aplicação \acrshort{csr}, a renderização ocorre predominantemente no navegador do usuário, ao passo que na versão \acrshort{ssr}, o conteúdo HTML é pré-renderizado no servidor e enviado pronto ao cliente. Ambas as implementações foram submetidas a um protocolo de testes rigoroso para a coleta de dados, conforme detalhado na seção seguinte, permitindo uma análise equitativa e baseada em evidências.


\section{Coleta de Dados e Testes}
\label{sec:coleta-de-dados-e-testes}

Esta seção descreve o procedimento de coleta e análise dos dados obtidos a partir da comparação entre as aplicações desenvolvidas com \english{\acrshort{csr}} e \english{\acrshort{ssr}}. O objetivo é mensurar o desempenho, a eficiência e a experiência do usuário proporcionada por cada aplicação sob condições controladas.

\subsection{Definição das Métricas}

A medição de desempenho em aplicações web modernas evoluiu de uma simples análise do tempo de carregamento total para uma avaliação multifacetada da experiência do usuário (UX). Para padronizar essa medição, o Google introduziu a iniciativa Web Vitals, um conjunto de métricas que quantificam aspectos cruciais da jornada do usuário. O subconjunto mais importante, conhecido como Core Web Vitals, foca em três pilares da experiência: o carregamento (medido pelo \acrshort{lcp}), a interatividade (medida pelo \acrshort{inp}) e a estabilidade visual (medida pelo \acrshort{cls}).

Adotando essa metodologia como padrão de mercado, este trabalho selecionou um conjunto de indicadores para realizar uma avaliação completa, abrangendo não apenas a percepção do usuário, mas também os custos computacionais no servidor. Para garantir uma análise estruturada, as métricas foram categorizadas da seguinte forma:

\begin{itemize}
\item \textbf{Web Vitals (Núcleo):} Representam a base da análise de experiência do usuário. Foram coletadas as métricas \acrshort{ttfb}, \acrshort{fcp}, \acrshort{lcp}, \acrshort{cls} e \acrshort{inp}. Esses dados foram registrados diretamente no cliente durante a navegação real e persistidos em formato NDJSON para análise posterior.

\item \textbf{Auditoria de Laboratório (Apoio):} Utilizando o Lighthouse, foram realizadas auditorias complementares para analisar o \textit{Total Blocking Time} (\acrshort{tbt}) e identificar oportunidades de otimização. As auditorias também validaram aspectos de Acessibilidade e \acrshort{seo} de forma automatizada.

\item \textbf{Recursos do Servidor (Custo):} Para contextualizar o custo de execução de cada abordagem, o consumo de recursos dos contêineres foi monitorado com o comando \texttt{docker stats}, registrando o uso de CPU e memória durante os testes.
\end{itemize}




\noindent
Adicionalmente, foram observados: \textbf{número de requisições HTTP} e \textbf{uso de cache} (no cliente), bem como \textbf{consumo de recursos} do contêiner (CPU e memória) durante os testes. O \acrfull{tti} foi empregado apenas como métrica de \textit{laboratório} via Lighthouse, não integrando o conjunto atual de Core Web Vitals. O tratamento estatístico detalhado das métricas será apresentado posteriormente.

\subsection{Ferramentas de Teste}

Foram utilizadas ferramentas complementares, com ênfase na coleta contínua no navegador (\textit{field}) e apoio de auditoria em \textit{laboratório}:

\begin{itemize}
    \item \textbf{Web Vitals (\acrfull{rum})}: Instrumentação no cliente para TTFB, FCP, LCP, CLS e INP, com envio via \texttt{navigator.sendBeacon} a um endpoint interno e persistência em formato NDJSON;
    \item \textbf{Google Lighthouse} (auxiliar): Auditoria em \textit{laboratório} para Performance (incluindo FCP, LCP, CLS, Speed Index e TBT), executada localmente sobre os serviços em Docker;
    \item \textbf{Chrome DevTools}: Inspeção de rede, \textit{waterfall}, cache e verificação dos \textit{POSTs} de métricas;
    \item \textbf{docker stats}: Acompanhamento do uso de CPU e memória dos contêineres durante a execução dos testes.
\end{itemize}

\subsection{Ambiente de Testes}

Os testes foram realizados em \textbf{ambiente local controlado} com contêineres \textit{Docker} para as duas versões (\acrshort{csr} e \acrshort{ssr}). Essa decisão decorre de limitações práticas da \textbf{NewsAPI} em produção ( políticas de CORS/uso do plano), e visa garantir controle experimental e reprodutibilidade. Ambos os serviços foram executados com \textbf{paridade de recursos}:

\begin{itemize}
    \item \textbf{CPU}: \texttt{--cpus="1.0"} e \texttt{--cpuset-cpus="0"};
    \item \textbf{Memória}: \texttt{--memory="1g"} e \texttt{--memory-swap="1g"};
    \item \textbf{Sistema de arquivos}: \texttt{--read-only} com \texttt{--tmpfs /tmp};
    \item \textbf{Persistência de métricas}: volume em \texttt{/data} com \texttt{METRICS\_PATH=/data/webvitals.ndjson}.
\end{itemize}

\noindent
A aplicação \acrshort{ssr} (Next.js) foi empacotada em modo \textit{standalone}. A aplicação \acrshort{csr} (React + Vite) foi servida por um processo \texttt{Node.js} simples que também expõe o endpoint de métricas. Os serviços públicos locais utilizados nos testes foram:
\begin{itemize}
    \item \textbf{SSR/Next.js}: \texttt{http://localhost:3001}
    \item \textbf{CSR/React}: \texttt{http://localhost:3002}
\end{itemize}

\subsection{Execução dos Testes}

A execução foi conduzida da seguinte forma:
\begin{enumerate}
    \item \textbf{Aquecimento}: duas visitas iniciais à mesma rota em cada aplicação, para estabilização de caches e recursos;
    \item \textbf{Coleta principal (Web Vitals)}: navegação real em janela anônima, registrando TTFB, FCP, LCP, CLS e INP por meio do endpoint interno e persistindo em arquivo NDJSON;
    \item \textbf{Coleta auxiliar (Lighthouse)}: auditorias repetidas em modo desktop, com parâmetros de \textit{throttling} consistentes entre cenários, para fornecer referência de \textit{laboratório};
    \item \textbf{Observabilidade do contêiner}: monitoramento pontual com \texttt{docker stats} para CPU e memória durante as execuções.
\end{enumerate}

\noindent
Para reduzir variabilidade, cada teste foi repetido \textbf{no mínimo cinco vezes} por cenário. A quantidade total de repetições e o método de agregação (mediana/p50 e p95) são detalhados em seção específica de resultados.

\subsection{Registro e Organização dos Dados}

Os dados coletados pela instrumentação (\acrshort{rum}) foram armazenados em arquivos \textbf{NDJSON} separados por abordagem, contendo os campos de identificação da métrica, valor e carimbo temporal. As auditorias do Lighthouse foram salvas em arquivos JSON/HTML para futura referência. Em seguida, os dados foram consolidados em planilhas, organizados por data, métrica e abordagem (CSR/SSR), para posterior análise comparativa.

\subsection{Método de Análise}

Os valores foram analisados por meio de \textbf{estatísticas descritivas}, com foco em \textbf{mediana (p50)} e \textbf{p95}, além de médias e desvios padrão quando apropriado. As comparações entre \acrshort{csr} e \acrshort{ssr} foram conduzidas métrica a métrica (TTFB, FCP, LCP, CLS e INP), considerando os \textit{trade-offs} de cada abordagem. Gráficos e tabelas de síntese são apresentados na seção de Resultados e Discussões.
